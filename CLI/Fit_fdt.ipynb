{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import least_squares, minimize\n",
    "from scipy.misc import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run GPU DSM\n",
    "\n",
    "Check the input input file for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('input.dat', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./gpu_DSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit $f_d(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow only slip-links created by SD from their individual times of creation:\n",
    "\n",
    "\\begin{align}\n",
    "f_d(t) &= \\int\\int p^{\\textrm{eq}}\\left(\\tau^{\\textrm{CD}}\\right) p^{\\textrm{cr}}\\left(\\tau^{\\textrm{SD}}\\right) e^{-\\frac{t}{\\tau^{\\textrm{CD}}}} e^{-\\frac{t}{\\tau^{\\textrm{SD}}}} \\mathrm{d}\\tau^{\\textrm{CD}} \\mathrm{d}\\tau^{\\textrm{SD}} && \\\\\n",
    "&= \\int_0^\\infty p^{\\textrm{eq}}\\left(\\tau^{\\textrm{CD}}\\right) e^{-\\frac{t}{\\tau^{\\textrm{CD}}}} \\mathrm{d}\\tau^{\\textrm{CD}}\\,\\int_0^\\infty p^{\\textrm{cr}}\\left(\\tau^{\\textrm{SD}}\\right) e^{-\\frac{t}{\\tau^{\\textrm{SD}}}} \\mathrm{d}\\tau^{\\textrm{SD}} &&\n",
    "\\end{align}\n",
    "\n",
    "We give our code $p^{\\textrm{eq}}\\left(\\tau^{\\textrm{CD}}\\right)$ as an input and would like to know $p^{\\textrm{cr}}\\left(\\tau^{\\textrm{SD}}\\right)$ that comes out from code by fitting $f_d(t)$.\n",
    "\n",
    "If we don't know the relaxation spectrum a priori, we can start with the discrete spectrum\n",
    "\\begin{equation}\n",
    "p^{\\textrm{cr}}\\left(\\tau\\right) = \\sum_i g_i \\delta(\\tau - \\tau_i)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_0^\\infty p^{\\textrm{cr}}\\left(\\tau^{\\textrm{SD}}\\right) e^{-\\frac{t}{\\tau^{\\textrm{SD}}}} \\mathrm{d}\\tau^{\\textrm{SD}} = \\sum_i g_i e^{-\\frac{t}{\\tau_i}}\n",
    "\\end{equation}\n",
    "\n",
    "We are interested in $p^{\\textrm{eq}}\\left(\\tau\\right)$ and we need to convert our discrete fit\n",
    "\n",
    "\\begin{equation}\n",
    "p^{\\textrm{eq}}\\left(\\tau\\right) = \\frac{\\sum_i g_i \\tau_i \\delta\\left(\\tau - \\tau_i\\right)}{\\sum_i g_i \\tau_i} = \\sum_i g_i' \\delta\\left(\\tau - \\tau_i\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, read $f_d(t)$ from code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('fdt.dat') as f:\n",
    "    lines = f.readlines()\n",
    "    x = np.array([float(line.split()[0]) for line in lines])\n",
    "    y = np.array([float(line.split()[1]) for line in lines])\n",
    "\n",
    "tfinal=x[-1]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.set_title(\"Entanglement lifetime distribution\")\n",
    "ax1.set_xlabel(r'$t/\\tau_c$')\n",
    "ax1.set_ylabel(r'$f_d(t)$')\n",
    "\n",
    "ax1.plot(x,y, c='r', label=r'$f_d(t)$')\n",
    "\n",
    "leg = ax1.legend()\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Trim data to $t>0.1 \\tau_c $ and subsample it $\\times 10$ times to speed-up fitting **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "#Remove all zeros from data\n",
    "mask = y!=0\n",
    "x=x[mask]\n",
    "y=y[mask]\n",
    "\n",
    "#Cut data points on the left where they dont change much\n",
    "cutoff=find_nearest(x, 1e-2)\n",
    "x=x[cutoff:]\n",
    "y=y[cutoff:]\n",
    "#Subsample data\n",
    "x=x[0::10]\n",
    "y=y[0::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define model function, residuals and mean-squared error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fdt(time, params):\n",
    "    lambdaArr = np.split(params,2)[0]\n",
    "    gArr = np.split(params,2)[1]/np.sum(np.split(params,2)[1])\n",
    "    return np.dot(np.exp(-time/lambdaArr), gArr)\n",
    "\n",
    "def log_fdt(time,params):\n",
    "    lambdaArr = np.split(params,2)[0]\n",
    "    gArr = np.split(params,2)[1]/np.sum(np.split(params,2)[1])\n",
    "    return logsumexp(-time/lambdaArr, b=gArr)\n",
    "\n",
    "#Vectorize function fdt and log_fdt\n",
    "fdtvec=np.vectorize(fdt, excluded=['params'])\n",
    "logfdtvec=np.vectorize(log_fdt, excluded=['params'])\n",
    "\n",
    "#Define residuals\n",
    "def residuals_fdt(param):\n",
    "    return fdtvec(time=x, params=param)-y\n",
    "\n",
    "def residuals_log_fdt(param):\n",
    "    #print(logfdtvec(time=x[:-1], params=param)-np.log(y[:-1]))\n",
    "    if np.any(fdtvec(time=x[:-1], params=param) < 0):\n",
    "        return np.full(x[:-1].shape,1e8) #Penalty for negative f_d(t)\n",
    "    else:\n",
    "        return logfdtvec(time=x[:-1], params=param)-np.log(y[:-1])\n",
    "\n",
    "def MSE(param):\n",
    "    return np.dot(residuals_fdt(param),residuals_fdt(param))/np.size(x)\n",
    "\n",
    "def log_MSE(param):\n",
    "    return np.dot(residuals_log_fdt(param),residuals_log_fdt(param))/np.size(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing strategy:\n",
    "1. Start with some big number of modes, like $n_{modes}=15$\n",
    "2. Run the least square optimization with standard residuals $y_i-f(x_i)$.\n",
    "3. Scan through different number of modes down to 1.\n",
    "4. If fit results have any negative weights, $g_i<0$, ignore\n",
    "5. If fit results have all positive weights, run the least square optimization with log-residuals\n",
    "6. Choose the best result among step 5\n",
    "\n",
    "## Use SciPy numeric least square minimization algorithm\n",
    "\n",
    "** First, optimize using standard residuals $y_i-f(x_i)$ **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fits_1 = [] #output of fitting function for all tested numbers of modes\n",
    "successful_fits_1 = [] #number of modes for successful fits\n",
    "for nmodes in range(1, 15):\n",
    "    lambdaArrInit=10.0**((np.array(range(nmodes), float) + 1.0)/nmodes*np.log10(tfinal))\n",
    "    gArrInit=np.full(nmodes, 1.0/nmodes)\n",
    "\n",
    "    fit = least_squares(residuals_fdt, np.append(lambdaArrInit, gArrInit), xtol=1e-15)\n",
    "    fits_1.append(fit)\n",
    "    if fit.success and not np.any(fdtvec(time=x, params=fit.x) < 0):\n",
    "        successful_fits_1.append(nmodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "successful_fits_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Next, optimize solution which have no negative weights further using log-residuals $\\log(y_i)-\\log(f(x_i))$ to find best fit for the longest relaxation tail **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fits_2 = [] #output of fitting function for all tested numbers of modes\n",
    "min_log_SME = log_MSE(fits_1[successful_fits_1[0]-1].x)\n",
    "best_nmodes = successful_fits_1[0]\n",
    "for i in successful_fits_1:\n",
    "    fit = fits_1[i-1]\n",
    "    print('nmodes\\t{0}'.format(i))\n",
    "    print(fit.message)\n",
    "    print('Initial guess MSE\\t{0}'.format(MSE(np.append(lambdaArrInit, gArrInit))))\n",
    "    print('Fit MSE\\t\\t\\t{0}'.format(MSE(fit.x)))\n",
    "\n",
    "    fit2 = least_squares(residuals_log_fdt, fit.x, xtol=1e-14, ftol=1e-14)\n",
    "    fits_2.append(fit2)\n",
    "\n",
    "    if fit2.success:\n",
    "        if log_MSE(fit2.x)<min_log_SME:\n",
    "            min_log_SME = log_MSE(fit2.x)\n",
    "            best_fit = fit2\n",
    "            best_nmodes = i\n",
    "        print(fit2.message)\n",
    "        print('First fit log-MSE\\t{0}'.format(log_MSE(fit.x)))\n",
    "        print('Second fit log-MSE\\t{0}'.format(log_MSE(fit2.x)))\n",
    "\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_nmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_fit.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit = fits_1[8-1]\n",
    "fit2 = best_fit\n",
    "\n",
    "fig3 = plt.figure(figsize=(24, 6))\n",
    "\n",
    "ax0 = fig3.add_subplot(131)\n",
    "\n",
    "ax0.set_title(r'$p^{cr}\\left(\\tau\\right)$')\n",
    "ax0.set_xlabel(r'$\\lambda$')\n",
    "ax0.set_ylabel(r'$g$')\n",
    "\n",
    "ax0.scatter(lambdaArrInit,gArrInit, c='k', label=r'Initial guess')\n",
    "ax0.scatter(np.split(fit.x,2)[0], np.split(fit.x,2)[1]/np.sum(np.split(fit.x,2)[1]), c='r', label=r'First fit')\n",
    "ax0.scatter(np.split(fit2.x,2)[0],np.split(fit2.x,2)[1]/np.sum(np.split(fit2.x,2)[1]), c='b', label=r'Second fit')\n",
    "leg = ax0.legend()\n",
    "ax0.set_xscale('log')\n",
    "\n",
    "ax1 = fig3.add_subplot(132)\n",
    "\n",
    "ax1.set_title(\"Check results of the fit\")\n",
    "ax1.set_xlabel(r'$t/\\tau_c$')\n",
    "ax1.set_ylabel(r'log residuals')\n",
    "\n",
    "ax1.plot(x,fdtvec(time=x, params=np.append(lambdaArrInit, gArrInit)), c='k', label=r'Initial guess')\n",
    "ax1.plot(x,fdtvec(time=x, params=fit.x), c='r', label=r'First fit')\n",
    "ax1.plot(x,fdtvec(time=x, params=fit2.x), c='b', label=r'Second fit')\n",
    "ax1.plot(x,y, c='g', label=r'$f_d(t)$')\n",
    "\n",
    "leg = ax1.legend()\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "ax2 = fig3.add_subplot(133)\n",
    "\n",
    "ax2.set_title(r'$f_d(t)$')\n",
    "ax2.set_xlabel(r'$t/\\tau_c$')\n",
    "ax2.set_ylabel(r'$f_d(t)$')\n",
    "\n",
    "ax2.plot(x,fdtvec(time=x, params=np.append(lambdaArrInit, gArrInit)), c='k', label=r'Initial guess')\n",
    "ax2.plot(x,fdtvec(time=x, params=fit.x), c='r', label=r'First fit')\n",
    "ax2.plot(x,fdtvec(time=x, params=fit2.x), c='b', label=r'Second fit')\n",
    "ax2.plot(x,y, c='g', label=r'Simulation data')\n",
    "leg = ax2.legend()\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equilibrium spectrum $p^{\\textrm{eq}}\\left(\\tau\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li=np.split(fit2.x,2)[0]\n",
    "gi=np.multiply(np.split(fit2.x,2)[0], np.split(fit2.x,2)[1]/np.sum(np.split(fit2.x,2)[1]))/np.dot(np.split(fit2.x,2)[0], np.split(fit2.x,2)[1]/np.sum(np.split(fit2.x,2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig8 = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax1 = fig8.add_subplot(111)\n",
    "\n",
    "ax1.set_title(\"Multimode $f_d(t)$ fitting\")\n",
    "ax1.set_xlabel(r'$\\lambda$')\n",
    "ax1.set_ylabel(r'$g^\\prime$')\n",
    "\n",
    "ax1.scatter(li,gi, c='r', label=r'Best SciPy fit')\n",
    "leg = ax1.legend()\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Shape of the discrete equilibrium spectrum is similar to two linear pieces. We may try to identify them using Ramer-Douglas-Peucker algorithm **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    return  sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "def point_line_distance(point, start, end):\n",
    "    if (start == end):\n",
    "        return distance(point, start)\n",
    "    else:\n",
    "        n = abs(\n",
    "            (end[0] - start[0]) * (start[1] - point[1]) - (start[0] - point[0]) * (end[1] - start[1])\n",
    "        )\n",
    "        d = sqrt(\n",
    "            (end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2\n",
    "        )\n",
    "        return n / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Find the farthest point from the line connecting first and last point in the spectrum **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmax = 0.0\n",
    "index = 0\n",
    "for i in range(1, len(li) - 1):\n",
    "    d = point_line_distance((np.log(li[i]),gi[i]), (np.log(li[0]),gi[0]), (np.log(li[-1]),gi[-1]))\n",
    "    if d > dmax:\n",
    "        index = i\n",
    "        dmax = d\n",
    "(np.log(li[index]),gi[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define bilinear BSW spectrum **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biliniear_spectrum(t, params):\n",
    "    if (t > params[1] and t < params[2]):\n",
    "        return params[0] + params[4] * np.log(t)\n",
    "    elif (t > params[2] and t < params[3]):\n",
    "        return params[0] + params[4] * np.log(params[2]) + params[5] * (np.log(t)-np.log(params[2]))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Initial guess from multimode discrete spectrum **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_bsw=(gi[0], li[0], li[index], li[-1],(gi[index]-gi[0])/(np.log(li[index])-np.log(li[0])),(gi[-1]-gi[index])/(np.log(li[-1])-np.log(li[index])))\n",
    "bilinear_spectrum_vec=np.vectorize(biliniear_spectrum, excluded=['params'])\n",
    "\n",
    "fig9 = plt.figure(figsize=(16, 6))\n",
    "\n",
    "ax0 = fig9.add_subplot(111)\n",
    "\n",
    "lArray=10**(-3+(np.array(range(1001), float)/1000)*10)\n",
    "ax0.plot(lArray,bilinear_spectrum_vec(t=lArray, params=initial_bsw), c='k')\n",
    "ax0.scatter(li,gi, c='r', label=r'Best SciPy fit')\n",
    "ax0.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx=np.array([  1.45923427e+00, 1.61190929e+01, 1.36688873e+02,   1.87906141e+03, 1.91862505e+03, 2.79666803e+02, 3.42043662e+01, 7.83363901e+00, 1.65242567e+01, -1.48560755e+01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.reshape(xx,(2,5)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda_kernel",
   "language": "python",
   "name": "anaconda_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
